# üì¶ Experiment Bundle ‚Äì YAML alap√∫ prompt-teszt egys√©g

Ez a form√°tum egyetlen `.yaml` f√°jlban r√∂gz√≠ti a teljes prompt-futtat√°si pr√≥b√°lkoz√°s minden fontos komponens√©t:
- **prompt** (sz√∂veg vagy f√°jlb√≥l)
- **input** (egyedi vagy batch)
- **model inform√°ci√≥**
- **expected vs actual output**
- **valid√°ci√≥s eredm√©ny**
- **log √©s metaadatok**

## üéØ C√©lja

- **Reproduk√°lhat√≥s√°g:** mindig tudd, milyen prompt √©s milyen modellel gener√°ltad az outputot.
- **Transzparencia:** minden √∂sszetev≈ë egy helyen ‚Äì ember √©s g√©p is k√∂nnyen olvassa.
- **Debug / review / dokument√°ci√≥:** prompt tuning, tesztel√©s √©s QA sor√°n k√∂nnyen visszak√∂vethet≈ë legyen minden.
- **Batch feldolgoz√°sra is alkalmas.**

## üß© F√°jlstrukt√∫ra

```yaml
prompt:                  # prompt sz√∂veg vagy f√°jlhivatkoz√°s
  purpose: "clarity scoring baseline"
  source: prompts/s1_v1.yaml
  text: |
    You are a clarity scorer...
input:                   # input egyedi vagy csv-batch
  format: yaml
  content:
    note: "tej"
model:                   # pontos modell setup
  provider: openai
  name: gpt-4
  version: 0613
  temperature: 0.2
  max_tokens: 512
  system_prompt: "You are a helpful assistant."
expected_output:         # mit v√°rtunk
  clarity_score: 60
  interpreted_text: null
actual_output:           # mit kaptunk vissza
  clarity_score: 45
  interpreted_text: "tej"
validation:              # automatikus √∂sszevet√©s eredm√©nye
  validator_profile: default
  result:
    status: failed
    mismatches:
      - field: clarity_score
        expected: 60
        actual: 45
log:                     # logf√°jl hivatkoz√°s
  status: failed
  path: logs/exp_001__log.md
meta:                    # kieg√©sz√≠t≈ë inform√°ci√≥k
  author: tamas
  created_at: "2025-05-29T20:20"
  tags: ["clarity", "step1", "LLM"]
