id: experiment__real_llm
step: step_01_scoring
model:
  type: llm
  provider: openai
  name: gpt-4.1-mini
prompt:
  purpose: Real LLM clarity scoring
  text: |
    You are a shopping assistant.
    Evaluate this input and return a clarity score (0â€“100).
    Input: {note}
input:
  format: yaml
  content:
    note: tej
initial_message: ""
expected_output:
  clarity_score: 60
  interpreted_text: null

actual_output:
  display_message: 'Clarity score: 0'
  parsed_response:
    tool_used: false
    tool_name: null
    tool_args: null
    message: 'Clarity score: 0'
  raw_response: !!python/object:langchain_core.messages.ai.AIMessage
    __dict__:
      content: 'Clarity score: 0'
      additional_kwargs:
        refusal: null
      response_metadata:
        token_usage:
          completion_tokens: 6
          prompt_tokens: 60
          total_tokens: 66
          completion_tokens_details:
            accepted_prediction_tokens: 0
            audio_tokens: 0
            reasoning_tokens: 0
            rejected_prediction_tokens: 0
          prompt_tokens_details:
            audio_tokens: 0
            cached_tokens: 0
        model_name: gpt-4.1-mini-2025-04-14
        system_fingerprint: fp_6f2eabb9a5
        id: chatcmpl-BcsvS0ckkcpvqvsIviVgoMeZIzSE3
        service_tier: default
        finish_reason: stop
        logprobs: null
      type: ai
      name: null
      id: run--53319d49-32ed-4f9b-a48d-c754c26526d1-0
      example: false
      tool_calls: []
      invalid_tool_calls: []
      usage_metadata:
        input_tokens: 60
        output_tokens: 6
        total_tokens: 66
        input_token_details:
          audio: 0
          cache_read: 0
        output_token_details:
          audio: 0
          reasoning: 0
    __pydantic_extra__: {}
    __pydantic_fields_set__: !!set
      usage_metadata: null
      response_metadata: null
      additional_kwargs: null
      invalid_tool_calls: null
      id: null
      tool_calls: null
      content: null
      name: null
    __pydantic_private__: null
validation:
  result:
    status: failed
    missing_fields:
    - clarity_score
    - interpreted_text
    mismatches: []
    unexpected_fields: []
    full_match: false
log:
  status: failed
  path: 05_logs\experiment_real_llm__log.md
meta:
  last_run: '2025-05-30T14:14:29'
  runner: runner
