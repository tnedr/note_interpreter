id: experiment__s1_01
step: step_01_scoring
prompt:
  purpose: Alap clarity scoring prompt
  source: ../../01_prompts/s1_v1.yaml
  text: 'You are a shopping assistant.

    Evaluate this input and return a clarity score (0â€“100).

    Input: {note}

    '
input:
  format: yaml
  content:
    note: tej
model:
  provider: openai
  name: gpt-4
  version: 395
  temperature: 0.2
  max_tokens: 512
  system_prompt: You are a helpful assistant.
expected_output:
  clarity_score: 60
  interpreted_text: null
actual_output:
  clarity_score: 50
  interpreted_text: TEJ
validation:
  result:
    status: failed
    missing_fields: []
    mismatches:
    - field: clarity_score
      expected: 60
      actual: 50
    - field: interpreted_text
      expected: null
      actual: TEJ
    unexpected_fields: []
    full_match: false
log:
  status: failed
  path: 05_logs\experiment_s1_01__log.md
meta:
  last_run: '2025-05-30T09:50:02'
  runner: runner
