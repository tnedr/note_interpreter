# ğŸ§ª Prompt Regression & Development Lab

## Overview / ÃttekintÃ©s

This project is a **modular, testable, and iterative framework** for developing and validating prompts used by LLM-based agents. It is designed as a *subproject* within a larger AI agent development ecosystem, and its goal is to ensure that prompts evolve in a controlled, regression-tested manner.

Ez a projekt egy **modulÃ¡ris, tesztelhetÅ‘ Ã©s iteratÃ­v framework** LLM-alapÃº Ã¼gynÃ¶kÃ¶k promptjainak fejlesztÃ©sÃ©hez Ã©s validÃ¡lÃ¡sÃ¡hoz. CÃ©lja, hogy a promptok kontrollÃ¡ltan, regressziÃ³mentesen fejlÅ‘djenek.

This lab provides the infrastructure to:
- Develop prompts in a structured and versioned way.
- Test prompts with realistic input scenarios.
- Execute lightweight agents with those prompts.
- Analyze and log the resulting outputs.
- Compare versions to detect regressions or improvements.

A fÅ‘ cÃ©l, hogy minden LLM-alapÃº Ã¼gynÃ¶k (agent) promptjai kÃ¶nnyen fejleszthetÅ‘k, tesztelhetÅ‘k Ã©s Ã¶sszehasonlÃ­thatÃ³k legyenek, valÃ³sÃ¡ghÅ± inputokkal Ã©s automatizÃ¡lt regressziÃ³s tesztekkel.

---

## Project Goals / ProjektcÃ©lok

- ğŸ§  Enable **prompt engineering as a software discipline**.
- ğŸ” Facilitate **prompt versioning and regression detection**.
- âš™ï¸ Leverage **simple, reusable core libraries**: `PromptBuilder`, `AgentCore`, `Logger`.
- ğŸ“¦ Isolate and test individual agent functionalities before full-scale integration.
- ğŸ’¡ Serve as a test harness and ideation space for advanced agent behavior.

- A prompt engineering szoftverfejlesztÃ©si diszciplÃ­nÃ¡vÃ¡ emelÃ©se
- VerziÃ³zÃ¡s, regressziÃ³detektÃ¡lÃ¡s
- ÃšjrahasznosÃ­thatÃ³ core library-k (`PromptBuilder`, `AgentCore`, `Logger`)
- FunkciÃ³k izolÃ¡lt tesztelÃ©se, Ã¶tletelÃ©s

---

## Project Structure / MappastruktÃºra

```plaintext
prompt-lab/
â”‚
â”œâ”€â”€ README.md â† This file
â”œâ”€â”€ architecture.md â† System description & data flow
â”‚
â”œâ”€â”€ agents/ â† Agent definitions + prompt versions
â”‚   â””â”€â”€ clarifier/
â”‚       â”œâ”€â”€ prompts/
â”‚       â”œâ”€â”€ test_cases/
â”‚       â””â”€â”€ metadata.yaml
â”œâ”€â”€ libs/ â† Reusable logic modules
â”‚   â”œâ”€â”€ prompt_builder.py
â”‚   â”œâ”€â”€ agent_core.py
â”‚   â””â”€â”€ logging_lib.py
â”œâ”€â”€ test_inputs/ â† Shared input components (notes, memory, etc.)
â”œâ”€â”€ results/ â† Test outputs, logs, and analysis results
â”œâ”€â”€ scripts/ â† Main runners and orchestrators
â”‚   â”œâ”€â”€ run_tests.py
â”‚   â”œâ”€â”€ evaluate_outputs.py
â”‚   â””â”€â”€ main.py â† Optional CLI entrypoint
â”œâ”€â”€ tests/ â† Unit tests for libs/
â””â”€â”€ configs/ â† Optional: Promptfoo, LangSmith configs, env vars
```

A rÃ©szletes tesztelÃ©si elveket Ã©s workflow-t lÃ¡sd: `docs/TESTING_MASTER_GUIDE.md`

---

## Core Workflow / FÅ‘ workflow

1. ğŸ›  **Define Agent Behavior**
   - Create or choose an agent folder in `agents/`
   - Add versioned prompts in `prompts/`
   - Add test cases in `test_cases/`

2. ğŸ§± **Build Prompt**
   - Use `PromptBuilder` to load and assemble prompt from YAML

3. ğŸ§  **Execute Agent**
   - Use `AgentCore` to run agent logic using the selected prompt

4. ğŸ“¤ **Input & Output**
   - Feed test input (note, memory, etc.)
   - Receive and log output using `Logger`

5. ğŸ”¬ **Evaluate Behavior**
   - Optionally define expected patterns or run diffing and scoring

---

## TesztelÃ©si architektÃºra Ã©s workflow (magyar rÃ©szletes leÃ­rÃ¡s)

A promptfejlesztÃ©s Ã©s -tesztelÃ©s folyamata a kÃ¶vetkezÅ‘ lÃ©pÃ©sekbÅ‘l Ã¡ll:

1. **PromptverziÃ³k kezelÃ©se:**  
   Minden Ã¼gynÃ¶k promptja kÃ¼lÃ¶n YAML fÃ¡jlban, verziÃ³zva talÃ¡lhatÃ³ a `prompts/` mappÃ¡ban.

2. **Teszt inputok:**  
   ValÃ³sÃ¡ghÅ±, vÃ¡ltozatos input YAML-ok a `test_inputs/` mappÃ¡ban (pl. notes, user memory, clarification history).

3. **AutomatizÃ¡lt tesztfuttatÃ¡s:**  
   A `run_prompt_tests.py` script minden promptverziÃ³t minden inputtal lefuttat, Ã©s naplÃ³zza az eredmÃ©nyeket.  
   - A script a PromptBuilder-t hasznÃ¡lja a prompt generÃ¡lÃ¡sÃ¡hoz.
   - Az LLM-et (pl. OpenAI GPT-4) hÃ­vja meg a generÃ¡lt prompttal.
   - Az outputokat logolja, opcionÃ¡lisan Ã¶sszeveti elvÃ¡rt eredmÃ©nyekkel.

4. **Promptfoo Ã©s LangSmith integrÃ¡ciÃ³:**  
   Ezek az eszkÃ¶zÃ¶k lehetÅ‘vÃ© teszik a promptok deklaratÃ­v, automatizÃ¡lt tesztelÃ©sÃ©t, valamint a webes playground hasznÃ¡latÃ¡t gyors iterÃ¡ciÃ³hoz.

5. **EredmÃ©nyek Ã©s regressziÃ³:**  
   Minden promptverziÃ³ra Ã©s inputra visszamenÅ‘leg is futnak a tesztek, Ã­gy azonnal lÃ¡thatÃ³, ha egy Ãºj promptverziÃ³ visszalÃ©pÃ©st okoz (regressziÃ³).

---

## Reusable Core Libraries

| Module           | Description                                      |
|------------------|--------------------------------------------------|
| `prompt_builder` | Builds prompt strings from versioned YAML files |
| `agent_core`     | Minimal agent interface for executing prompts   |
| `logging_lib`    | Logs test results, diffs, and evaluations       |

---

## Example Test Case Structure

```yaml
agent: clarifier
prompt_version: v1
input:
  note: "User asked about magnesium absorption"
  memory: "Known deficiencies"
expected:
  output_contains: ["magnesium", "absorption", "gut"]
```

---

## How To Run / FuttatÃ¡s

1. TelepÃ­tsd a fÃ¼ggÅ‘sÃ©geket:
   ```sh
   pip install -r requirements.txt  # vagy pipenv install -r prompt_testing/requirements.txt
   ```
2. Futtasd a teszteket:
   ```sh
   python scripts/run_tests.py
   # vagy
   pipenv run promptfoo test promptfoo.yaml --provider openai:gpt-4
   ```
3. Webes playground indÃ­tÃ¡sa:
   ```sh
   pipenv run promptfoo web
   ```
4. LangSmith hasznÃ¡lata:
   - RegisztrÃ¡lj a https://smith.langchain.com/ oldalon, Ã©s szerezd meg az API kulcsodat.
   - ÃllÃ­tsd be a kÃ¶rnyezeti vÃ¡ltozÃ³kat (pl. `.env`):
     ```
     LANGCHAIN_API_KEY=your-key-here
     LANGCHAIN_TRACING_V2=true
     ```
   - Futtasd a scriptet:
     ```sh
     pipenv run python langsmith_test.py
     ```

---

## Roadmap

- Automated similarity and structure-based output evaluation
- Prompt diff visualizations
- LangSmith or Promptfoo integration (optional)
- CI-ready architecture for regression automation

---

## Philosophy / FilozÃ³fia

Don't build monolith prompts. Build evolving, testable, intelligent components â€” just like great code.

Ne monolit promptokat Ã©pÃ­ts! Fejlessz evolÃºciÃ³s, tesztelhetÅ‘, intelligens komponenseket â€“ akÃ¡rcsak a jÃ³ kÃ³dot.

---

## Referencia
A rÃ©szletes tesztelÃ©si elveket Ã©s workflow-t lÃ¡sd: `docs/TESTING_MASTER_GUIDE.md` 