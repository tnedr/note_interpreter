# ğŸ§ª Prompt Regression & Development Lab

## Overview / ÃttekintÃ©s

This project is a **modular, testable, and iterative framework** for developing and validating prompts used by LLM-based agents. It is designed as a *subproject* within a larger AI agent development ecosystem, and its goal is to ensure that prompts evolve in a controlled, regression-tested manner.

**This lab is designed for _stepwise, multi-turn prompt development_: you can build, test, and version agents that interact with the user in multiple rounds, asking clarifying questions if needed, not just static one-shot prompts.**

**Ez a labor kifejezetten _lÃ©pÃ©senkÃ©nti, tÃ¶bbkÃ¶rÃ¶s promptfejlesztÃ©sre_ kÃ©szÃ¼lt: olyan agenteket lehet vele Ã©pÃ­teni Ã©s tesztelni, amelyek tÃ¶bb lÃ©pÃ©sben, pontosÃ­tÃ³ kÃ©rdÃ©sekkel, interaktÃ­van mÅ±kÃ¶dnek â€“ nem csak egyszerÅ±, statikus promptokat kezel.**

This lab provides the infrastructure to:
- Develop prompts in a structured and versioned way.
- Test prompts with realistic input scenarios.
- Execute lightweight agents with those prompts.
- Analyze and log the resulting outputs.
- Compare versions to detect regressions or improvements.

A fÅ‘ cÃ©l, hogy minden LLM-alapÃº Ã¼gynÃ¶k (agent) promptjai kÃ¶nnyen fejleszthetÅ‘k, tesztelhetÅ‘k Ã©s Ã¶sszehasonlÃ­thatÃ³k legyenek, valÃ³sÃ¡ghÅ± inputokkal Ã©s automatizÃ¡lt regressziÃ³s tesztekkel.

---

## Project Goals / ProjektcÃ©lok

- ğŸ§  Enable **prompt engineering as a software discipline**.
- ğŸ” Facilitate **prompt versioning and regression detection**.
- âš™ï¸ Leverage **simple, reusable core libraries**: `PromptBuilder`, `AgentCore`, `Logger`.
- ğŸ“¦ Isolate and test individual agent functionalities before full-scale integration.
- ğŸ’¡ Serve as a test harness and ideation space for advanced agent behavior.
- ğŸ§© **Stepwise, multi-turn agent logic**: Support for agents that clarify, iterate, and refine their output through multiple prompt rounds.
- **LÃ©pÃ©senkÃ©nti, tÃ¶bbkÃ¶rÃ¶s agent logika**: Olyan agentek tÃ¡mogatÃ¡sa, amelyek pontosÃ­tanak, visszakÃ©rdeznek, Ã©s tÃ¶bb lÃ©pÃ©sben adjÃ¡k meg a vÃ©gsÅ‘ vÃ¡laszt.

---

## Project Structure / MappastruktÃºra

```plaintext
prompt-lab/
â”‚
â”œâ”€â”€ README.md â† This file
â”œâ”€â”€ architecture.md â† System description & data flow
â”‚
â”œâ”€â”€ agents/ â† Agent definitions + prompt versions
â”‚   â””â”€â”€ clarifier/
â”‚       â”œâ”€â”€ prompts/
â”‚       â”œâ”€â”€ test_cases/
â”‚       â””â”€â”€ metadata.yaml
â”œâ”€â”€ libs/ â† Reusable logic modules
â”‚   â”œâ”€â”€ prompt_builder.py
â”‚   â”œâ”€â”€ agent_core.py
â”‚   â””â”€â”€ logging_lib.py
â”œâ”€â”€ test_inputs/ â† Shared input components (notes, memory, etc.)
â”œâ”€â”€ results/ â† Test outputs, logs, and analysis results
â”œâ”€â”€ scripts/ â† Main runners and orchestrators
â”‚   â”œâ”€â”€ run_tests.py
â”‚   â”œâ”€â”€ evaluate_outputs.py
â”‚   â””â”€â”€ main.py â† Optional CLI entrypoint
â”œâ”€â”€ tests/ â† Unit tests for libs/
â””â”€â”€ configs/ â† Optional: Promptfoo, LangSmith configs, env vars
```

A rÃ©szletes tesztelÃ©si elveket Ã©s workflow-t lÃ¡sd: `docs/TESTING_MASTER_GUIDE.md`

---

## Core Workflow / FÅ‘ workflow

1. ğŸ›  **Define stepwise agent behavior** â€“ not just static prompts, but multi-turn, clarification-capable agents.
2. ğŸ§± **Build Prompt** â€“ Use `PromptBuilder` to load and assemble prompt from YAML
3. ğŸ§  **Execute Agent** â€“ Use `AgentCore` to run agent logic using the selected prompt
4. ğŸ“¤ **Input & Output** â€“ Feed test input (note, memory, etc.), including multi-step clarification scenarios
5. ğŸ”¬ **Evaluate Behavior** â€“ Optionally define expected patterns or run diffing and scoring

**A workflow tÃ¡mogatja a tÃ¶bb lÃ©pÃ©ses, pontosÃ­tÃ³ kÃ©rdÃ©seket is tartalmazÃ³ agent pipeline-ok fejlesztÃ©sÃ©t Ã©s tesztelÃ©sÃ©t.**

---

## TesztelÃ©si architektÃºra Ã©s workflow (magyar rÃ©szletes leÃ­rÃ¡s)

A promptfejlesztÃ©s Ã©s -tesztelÃ©s folyamata a kÃ¶vetkezÅ‘ lÃ©pÃ©sekbÅ‘l Ã¡ll:

1. **PromptverziÃ³k kezelÃ©se:**  
   Minden Ã¼gynÃ¶k promptja kÃ¼lÃ¶n YAML fÃ¡jlban, verziÃ³zva talÃ¡lhatÃ³ a `prompts/` mappÃ¡ban.
2. **Teszt inputok:**  
   ValÃ³sÃ¡ghÅ±, vÃ¡ltozatos input YAML-ok a `test_inputs/` mappÃ¡ban (pl. notes, user memory, clarification history, tÃ¶bb lÃ©pÃ©ses pÃ©ldÃ¡k).
3. **AutomatizÃ¡lt tesztfuttatÃ¡s:**  
   A `run_prompt_tests.py` script minden promptverziÃ³t minden inputtal lefuttat, Ã©s naplÃ³zza az eredmÃ©nyeket.  
   - A script a PromptBuilder-t hasznÃ¡lja a prompt generÃ¡lÃ¡sÃ¡hoz.
   - Az LLM-et (pl. OpenAI GPT-4) hÃ­vja meg a generÃ¡lt prompttal.
   - Az outputokat logolja, opcionÃ¡lisan Ã¶sszeveti elvÃ¡rt eredmÃ©nyekkel.
4. **Promptfoo Ã©s LangSmith integrÃ¡ciÃ³:**  
   Ezek az eszkÃ¶zÃ¶k lehetÅ‘vÃ© teszik a promptok deklaratÃ­v, automatizÃ¡lt tesztelÃ©sÃ©t, valamint a webes playground hasznÃ¡latÃ¡t gyors iterÃ¡ciÃ³hoz.
5. **EredmÃ©nyek Ã©s regressziÃ³:**  
   Minden promptverziÃ³ra Ã©s inputra visszamenÅ‘leg is futnak a tesztek, Ã­gy azonnal lÃ¡thatÃ³, ha egy Ãºj promptverziÃ³ visszalÃ©pÃ©st okoz (regressziÃ³).

---

## Reusable Core Libraries

| Module           | Description                                      |
|------------------|--------------------------------------------------|
| `prompt_builder` | Builds prompt strings from versioned YAML files |
| `agent_core`     | Minimal agent interface for executing prompts   |
| `logging_lib`    | Logs test results, diffs, and evaluations       |

---

## Example Test Case Structure

```yaml
agent: clarifier
prompt_version: v1
input:
  note: "User asked about magnesium absorption"
  memory: "Known deficiencies"
  # clarification_history: ["Does the user have gut issues?"]
expected:
  output_contains: ["magnesium", "absorption", "gut"]
```

---

## How To Run / FuttatÃ¡s

1. TelepÃ­tsd a fÃ¼ggÅ‘sÃ©geket:
   ```sh
   pip install -r requirements.txt  # vagy pipenv install -r prompt_testing/requirements.txt
   ```
2. Futtasd a teszteket:
   ```sh
   python scripts/run_tests.py
   # vagy
   pipenv run promptfoo test promptfoo.yaml --provider openai:gpt-4
   ```
3. Webes playground indÃ­tÃ¡sa:
   ```sh
   pipenv run promptfoo web
   ```
4. LangSmith hasznÃ¡lata:
   - RegisztrÃ¡lj a https://smith.langchain.com/ oldalon, Ã©s szerezd meg az API kulcsodat.
   - ÃllÃ­tsd be a kÃ¶rnyezeti vÃ¡ltozÃ³kat (pl. `.env`):
     ```
     LANGCHAIN_API_KEY=your-key-here
     LANGCHAIN_TRACING_V2=true
     ```
   - Futtasd a scriptet:
     ```sh
     pipenv run python langsmith_test.py
     ```

---

## Roadmap

- Automated similarity and structure-based output evaluation
- Prompt diff visualizations
- LangSmith or Promptfoo integration (optional)
- CI-ready architecture for regression automation
- **Stepwise, multi-turn agent test harness and visualization**

---

## Philosophy / FilozÃ³fia

Don't build monolith prompts. Build evolving, testable, **stepwise**, intelligent components â€” just like great code.

Ne monolit promptokat Ã©pÃ­ts! Fejlessz evolÃºciÃ³s, tesztelhetÅ‘, **lÃ©pÃ©senkÃ©nt fejlÅ‘dÅ‘**, intelligens komponenseket â€“ akÃ¡rcsak a jÃ³ kÃ³dot.

---

## Referencia
A rÃ©szletes tesztelÃ©si elveket Ã©s workflow-t lÃ¡sd: `docs/TESTING_MASTER_GUIDE.md`

## Meta Input/Output â€“ The Prompt Lab as a System / Meta bemenet Ã©s kimenet

**Meta Input (what you give to the Prompt Lab):**
- **Agent definition:**  
  What is the agent's goal?  
  What are its expected inputs/outputs?  
  What is the stepwise prompt pipeline (how many steps, what happens in each)?
- **Prompt versions:**  
  YAML files describing each prompt step.
- **Test cases:**  
  Input scenarios (possibly multi-step), expected outputs, clarification flows.
- **Evaluation criteria:**  
  What counts as a "good" output? (e.g., must contain certain info, must ask clarification if ambiguous, etc.)

**Meta Output (what the Prompt Lab produces):**
- **Test results:**  
  For each agent version and test case, what was the output? Did it match expectations?
- **Logs and diffs:**  
  Detailed logs, output differences between prompt versions.
- **Regression reports:**  
  Did a new prompt version break anything?
- **Prompt evolution history:**  
  How did the agent's stepwise logic change over time?

---

**Meta bemenet (amit a Prompt Lab kap):**
- **Agens definÃ­ciÃ³:**  
  Mi az agent cÃ©lja?  
  Mik az elvÃ¡rt inputjai/outputjai?  
  Mi a stepwise prompt pipeline (hÃ¡ny lÃ©pÃ©s, mi tÃ¶rtÃ©nik egyes lÃ©pÃ©sekben)?
- **Prompt verziÃ³k:**  
  YAML fÃ¡jlok, amelyek minden prompt lÃ©pÃ©st leÃ­rnak.
- **Tesztesetek:**  
  Input szcenÃ¡riÃ³k (akÃ¡r tÃ¶bb lÃ©pÃ©sben), elvÃ¡rt outputok, clarification flow-k.
- **Ã‰rtÃ©kelÃ©si kritÃ©riumok:**  
  MitÅ‘l "jÃ³" egy output? (pl. tartalmaznia kell bizonyos infÃ³t, kÃ©rdezzen, ha nem egyÃ©rtelmÅ±, stb.)

**Meta kimenet (amit a Prompt Lab elÅ‘Ã¡llÃ­t):**
- **TeszteredmÃ©nyek:**  
  Minden agent verziÃ³ra Ã©s tesztesetre, mi lett az output? Megfelelt-e az elvÃ¡rÃ¡snak?
- **Logok Ã©s diffek:**  
  RÃ©szletes naplÃ³k, output kÃ¼lÃ¶nbsÃ©gek prompt verziÃ³k kÃ¶zÃ¶tt.
- **RegressziÃ³s riportok:**  
  TÃ¶rtÃ©nt-e visszalÃ©pÃ©s egy Ãºj prompt verziÃ³val?
- **Prompt pipeline evolÃºciÃ³:**  
  Hogyan vÃ¡ltozott az agent stepwise logikÃ¡ja az idÅ‘ sorÃ¡n?

---

**PÃ©lda:**

- Agent cÃ©lja: "A felhasznÃ¡lÃ³ jegyzetÃ©t Ã©rtelmezi, ha kell, pontosÃ­t."
- Stepwise pipeline:  
  1. LÃ©pÃ©s: note + memory â†’ ha nem egyÃ©rtelmÅ±, clarification kÃ©rdÃ©s  
  2. LÃ©pÃ©s: note + memory + clarification â†’ vÃ©gsÅ‘ output
- Teszteset:  
  "Buy milk" + "User often forgets groceries" â†’ "Do you need lactose-free milk?" â†’ "Yes" â†’ "User wants lactose-free milk."
- ElvÃ¡rt viselkedÃ©s: mindig kÃ©rdezzen, ha nem egyÃ©rtelmÅ±.
- Kimenet: teszteredmÃ©nyek, logok, diffek, regressziÃ³k, prompt pipeline evolÃºciÃ³.

--- 